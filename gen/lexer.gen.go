// Code generated by lexgen; DO NOT EDIT.
package twig

import (
	"fmt"
)

// Lexer tokenizes a template string
type Lexer struct {
	source string
	tokens []Token
	line   int
	col    int
	pos    int
}

// NewLexer creates a new lexer
func NewLexer(source string) *Lexer {
	return &Lexer{
		source: source,
		tokens: []Token{},
		line:   1,
		col:    1,
		pos:    0,
	}
}

// Tokenize tokenizes the source and returns tokens
func (l *Lexer) Tokenize() ([]Token, error) {
	// Skip if already tokenized
	if len(l.tokens) > 0 {
		return l.tokens, nil
	}

	for l.pos < len(l.source) {
		switch {
		case l.source[l.pos] == '\n':
			// Newline
			l.line++
			l.col = 1
			l.pos++
			
		case l.isWhitespace(l.source[l.pos]):
			// Skip whitespace
			l.col++
			l.pos++
			
		case l.match("{{"):
			// Variable start
			l.addToken(T_VAR_START, "{{")
			l.advance(2)
			
		case l.match("}}"):
			// Variable end
			l.addToken(T_VAR_END, "}}")
			l.advance(2)
			
		case l.match("{%"):
			// Block start
			l.addToken(T_BLOCK_START, "{%")
			l.advance(2)
			
		case l.match("%}"):
			// Block end
			l.addToken(T_BLOCK_END, "%}")
			l.advance(2)
			
		default:
			// Text content (anything that's not a special delimiter)
			start := l.pos
			for l.pos < len(l.source) && 
				!l.match("{{") && !l.match("}}") && 
				!l.match("{%") && !l.match("%}") {
				if l.source[l.pos] == '\n' {
					l.line++
					l.col = 1
				} else {
					l.col++
				}
				l.pos++
			}
			
			if start != l.pos {
				l.addToken(T_TEXT, l.source[start:l.pos])
			} else {
				// If we get here, we have an unrecognized character
				return nil, fmt.Errorf("unexpected character %q at line %d, column %d",
					l.source[l.pos], l.line, l.col)
			}
		}
	}

	// Add EOF token
	l.addToken(T_EOF, "")
	
	return l.tokens, nil
}

// Helper methods

func (l *Lexer) addToken(typ TokenType, value string) {
	l.tokens = append(l.tokens, Token{
		Type:  typ,
		Value: value,
		Line:  l.line,
		Col:   l.col - len(value),
	})
}

func (l *Lexer) advance(n int) {
	l.pos += n
	l.col += n
}

func (l *Lexer) match(s string) bool {
	if l.pos+len(s) > len(l.source) {
		return false
	}
	return l.source[l.pos:l.pos+len(s)] == s
}

func (l *Lexer) isWhitespace(c byte) bool {
	return c == ' ' || c == '\t' || c == '\r'
}